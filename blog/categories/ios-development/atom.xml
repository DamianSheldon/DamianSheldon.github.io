<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ios development | Hello World]]></title>
  <link href="http://DamianSheldon.github.io/blog/categories/ios-development/atom.xml" rel="self"/>
  <link href="http://DamianSheldon.github.io/"/>
  <updated>2018-06-30T20:43:35+08:00</updated>
  <id>http://DamianSheldon.github.io/</id>
  <author>
    <name><![CDATA[Sheldon]]></name>
    <email><![CDATA[dongmeilianghy@sina.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[多线程的 Core Data]]></title>
    <link href="http://DamianSheldon.github.io/blog/concurrency-with-core-data.html"/>
    <updated>2018-02-23T16:00:35+08:00</updated>
    <id>http://DamianSheldon.github.io/blog/concurrency-with-core-data</id>
    <content type="html"><![CDATA[<p>平常在项目中没有使用过 Core Data, 因为我觉得它的学习曲线还挺陡峭，整个框架给人的感觉很复杂和笨重，因此一直没有使用它。但是看到喵神这份<a href="https://onevcat.com/2013/04/ios-interview/">上级向的十个 iOS 开发面试题</a>中和这份<a href="http://studentdeng.github.io/blog/2014/02/11/baidu-interview/">百度面试</a>题中都有涉及到 Core Data 的内容，我想还是有必要好好研究一下它，毕竟它是 Apple 官方的持久化方案，我们可以取其精华，弃其糟粕，另一方面未来我们也可能因为各种原因接手或参与使用 Core Data 的项目。</p>

<p>这篇文章主要想探讨上面提到的面试题中的两个关于 Core Data 的问题:</p>

<ol>
<li>你实现过多线程的Core Data么？NSPersistentStoreCoordinator，NSManagedObjectContext和NSManagedObject中的哪些需要在线程中创建或者传递？你是用什么样的策略来实现的？</li>
<li>Core Data：中多线程中处理大量数据同步时的操作。</li>
</ol>


<p>在回答这两个问题之前，我们先看 Apple 是怎么告诉我们使用多线程的 Core Data 的，在最新的(2017-03-27) Core Data Programming Guide 中有一节 Concurrency with Core Data，它没有直接说如何使用多线程，只是说了 managed object context 在多线程中的两种使用模式:</p>

<blockquote><p>In Core Data, the managed object context can be used with two concurrency patterns, defined by NSMainQueueConcurrencyType and NSPrivateQueueConcurrencyType.</p>

<p>NSMainQueueConcurrencyType is specifically for use with your application interface and can only be used on the main queue of an application.</p>

<p>The NSPrivateQueueConcurrencyType configuration creates its own queue upon initialization and can be used only on that queue. Because the queue is private and internal to the NSManagedObjectContext instance, it can only be accessed through the performBlock: and the performBlockAndWait: methods.</p></blockquote>

<!--more-->


<p>对于多线程中对象的传递则有这么一段描述:</p>

<blockquote><p>NSManagedObject instances are not intended to be passed between queues. Doing so can result in corruption of the data and termination of the application. When it is necessary to hand off a managed object reference from one queue to another, it must be done through NSManagedObjectID instances.</p>

<p>You retrieve the managed object ID of a managed object by calling the objectID method on the NSManagedObject instance.</p></blockquote>

<p>从这里我们知道，NSManagedObject 是不能在线程中传递的，必须重新创建。但是对于 NSPersistentStoreCoordinator 和 NSManagedObjectContext 是需要创建还是可以传递就不是很清楚。</p>

<p>于是我又通读了全篇，说实话我看完以后还是没搞明白该如何使用多线程的 Core Data，于是我又找了 Apple 提供的多线程的 Core Data 示例代码 <a href="https://developer.apple.com/library/content/samplecode/ThreadedCoreData/Introduction/Intro.html#//apple_ref/doc/uid/DTS40010723">ThreadedCoreData</a>，它展示了一种使用多线程的 Core Data 的方法，但是并不能解答如何使用多线程的 Core Data。因为可能还有很多其他的方法，我们要溯本求源，找到问题的关键，问题才能迎刃而解。 于是我又到 <a href="https://objccn.io">objc 中国</a>上查找，里面专门有一个 Core Data 的专题，先看了一遍<a href="https://objccn.io/issue-4-5/">导入大数据集</a>，它提供了一些解答问题2的素材，我们稍候将它总结为答案，同时它还提供了新的线索 &ndash; <a href="http://objccn.io/issue-2-2/">在后台使用 Core Data</a>，于是我又看了这篇文章。</p>

<p>这篇文章提到在使用多线程的 Core Data 时，强烈建议先通读 Apple 的官方文档 Concurrency with Core Data，这也是符合学习 iOS 开发新知识的路线的，毕竟所有的知识都源于 Apple，这种方法推荐给大家，而我一开始也是这么做的，这里的问题是 Apple 的文档一直在更新，有的内容在新版本文档中被删除了，那么我们有办法找到旧版本的文档吗？</p>

<p>有的，这里介绍一种方法，虽然 Apple 不提供旧版本的文档，但是有个网址&ndash;<a href="https://archive.org/web/">Internet Archive</a>它会定期备份整个互联网上重要的网址，所以我们可以结合文档的修改历史在这里找到旧版本的文档，我们看到在后台使用 Core Data 翻译于 2014/03/22，我们不妨先试下 2014-03-10 这个版本的 Core Data Programming Guide.</p>

<p>这个版本是这么介绍如何使用多线程的 Core Data 的:</p>

<blockquote><p>The pattern recommended for concurrent programming with Core Data is thread confinement : each thread must have its own entirely private managed object context.</p>

<p>There are two possible ways to adopt the pattern:</p>

<ol>
<li>Create a separate managed object context for each thread and share a single persistent store coordinator.</li>
</ol>


<p>This is the typically-recommended approach.</p>

<ol>
<li>Create a separate managed object context and persistent store coordinator for each thread.</li>
</ol>


<p>This approach provides for greater concurrency at the expense of greater complexity (particularly if you need to communicate changes between different contexts) and increased memory usage.</p></blockquote>

<p>个人认为这个版本的介绍更清晰明了，也更容易得出问题的答案：</p>

<p>NSManagedObjectContext 和 NSManagedObject 是需要在线程中创建的，而 NSPersistentStoreCoordinator 是推荐传递的。策略则是创建两个线程，不妨分别称它们为工作线程和后台线程，工作线程为主，后台线程为辅，它们分别创建自己独立的 managed object context，然后共享同一个 persistent store coordinator,工作线程关注 NSManagedObjectContextDidSaveNotification 通知，当后台线程保存更改时，它便收到通知然后合并更改。代码示例如下：</p>

<pre><code class="objc">// Worker Thread
_mainManagedObjectContext = [[NSManagedObjectContext alloc] initWithConcurrencyType:NSMainQueueConcurrencyType];
 // observe the APLEarthQuakeSource save operation with its managed object context
 [[NSNotificationCenter defaultCenter] addObserver:self
                                             selector:@selector(mergeChanges:)
                                                 name:NSManagedObjectContextDidSaveNotification
                                               object:nil];

// merge changes to main context,fetchedRequestController will automatically monitor the changes and update tableview.
- (void)updateMainContext:(NSNotification *)notification {

    assert([NSThread isMainThread]);
    [self.managedObjectContext mergeChangesFromContextDidSaveNotification:notification];
}

// this is called via observing "NSManagedObjectContextDidSaveNotification" from our APLEarthQuakeSource
- (void)mergeChanges:(NSNotification *)notification {
    NSLog(@"merge changes be invoked on thread:%@", [NSThread currentThread]);

    if (notification.object != self.managedObjectContext) {
        [self performSelectorOnMainThread:@selector(updateMainContext:) withObject:notification waitUntilDone:NO];
    }
}

// Background Thread
NSManagedObjectContext *private = [[NSManagedObjectContext alloc] initWithConcurrencyType:NSPrivateQueueConcurrencyType];

[private performBlock:^{ 
    // Do some work
    NSError *error = nil;

    if (![private save:&amp;error]) {
        // Handle error
    }
}]
</code></pre>

<p>这里还补充说明下 managed object context 的并发类型，我们可以用 NSMainQueueConcurrencyType 和 NSPrivateQueueConcurrencyType 来指定它的类型，按照 Apple API reference 中的说明:</p>

<blockquote><p>You use contexts using the queue-based concurrency types in conjunction with performBlock: and performBlockAndWait:. You group “standard” messages to send to the context within a block to pass to one of these methods. There are two exceptions:</p>

<p>  • Setter methods on queue-based managed object contexts are thread-safe. You can invoke these methods directly on any thread.</p>

<p>  • If your code is executing on the main thread, you can invoke methods on the main queue style contexts directly instead of using the block based API.</p></blockquote>

<p>我们可以知道 context 是结合 performBlock: 和 performBlockAndWait: 来使用并发类型的，也就是说 NSMainQueueConcurrencyType 时这两个方法是在主队列上执行 block, 而 NSPrivateQueueConcurrencyType 则是在私有队列上执行。从这里我们推出工作线程的 context 使用 NSMainQueueConcurrencyType 而后台线程的 context 使用 NSPrivateQueueConcurrencyType 应该是比较好的实践，因为我们使用多线程，必然是想获得多线程的好处，如果还指定 context 为 NSMainQueueConcurrencyType，则工作还是在主线程上，并没有被移交到子线程，实际上仍然是单线程。</p>

<p>接下来我们来看第二个问题：</p>

<ul>
<li>Core Data：中多线程中处理大量数据同步时的操作。</li>
</ul>


<p>要想回答这个问题，我们得知道处理大量数据同步时会遇到什么问题，这样才能有的放矢。上面提到<a href="https://objccn.io/issue-4-5/">导入大数据集</a> 提供了回答此问题的素材，再结合<a href="http://objccn.io/issue-2-2/">在后台使用 Core Data</a>，我觉得可以得到问题的一个答案：</p>

<p>如果大量数据的同步不需要反映到界面上，那么我们可以创建一个线程并为它配置独立的 Core Data 栈，然后批量保存；如果需要反映到界面上，则要合并修改通知再更新界面，防止界面陷入卡顿。</p>

<p>正如喵神所说面试中的技术问题环节不仅是企业对应聘者技能和积累的考察，也是一个开发者自我检验的好机会。而且面试中的技术问题通常是关于某知识点的难点，即使是我们经常使用的知识，如果我们没有仔细深入地思考可能也答不上来，所以我觉得利用面试题来提高自己的技术水平和加深对某知识的掌握是不错的方法。</p>

<h3>Reference</h3>

<ul>
<li>Core Data Programming Guide</li>
<li><a href="https://objccn.io/issue-4-5/">导入大数据集</a></li>
<li><a href="https://objccn.io/issue-2-2/">常见的后台实践</a></li>
<li><a href="https://blog.codecentric.de/en/2014/11/concurrency-coredata/">Concurrency with CoreData</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[圆锥渐变的一种简单实现]]></title>
    <link href="http://DamianSheldon.github.io/blog/a-simple-conical-gradient-on-ios.html"/>
    <updated>2017-09-22T15:59:35+08:00</updated>
    <id>http://DamianSheldon.github.io/blog/a-simple-conical-gradient-on-ios</id>
    <content type="html"><![CDATA[<p>Core Graphics 支持两种渐变：线性(Axial)和径向(Radial)渐变，但是有的时候我们可能会用到圆锥(Conical)渐变，例如在扫描附近的目标时，交互可能用上带这种渐变的雷达效果，它长这样：</p>

<p><img src="../images/Conical-1.png" title="&lsquo;Conical-1&rsquo;" ><br/>
<img src="../images/Conical-2.png" title="&lsquo;Conical-2&rsquo;" ></p>

<p>要实现这样一种渐变你会怎么做呢？我的想法是从渐变的本质着手。渐变是从一种颜色渐渐变化成另外一种颜色，而圆锥渐变是根据角度渐渐变化。我们把界面看成位图，这样可以由点的位置得到它的角度，继而根据角度线性插值可以得到它的颜色，最终就可以得到圆锥渐变。</p>

<p>想法有了，接下来我们用它来实现上图中 Find My iPhone 图标的雷达效果吧。</p>

<p>首先定义一个 CALayer 的子类 ConicalLayer，</p>

<!--more-->


<pre><code>// ConicalLayer.h
@interface ConicalLayer : CALayer

/// An array of CGColorRef objects defining the color of each gradient stop. 
@property(copy) NSArray *colors;

@end

// ConicalLayer.m
- (id)init
{
    if (!(self = [super init])) {
        return nil;
    }

    _needsDisplayOnBoundsChange = YES;

    return self;
}

- (void)drawInContext:(CGContextRef)ctx
{
    // Draw background
    CGRect rect = CGContextGetClipBoundingBox(ctx);
    CGContextSetFillColorWithColor(ctx, self.backgroundColor);
    CGContextFillRect(ctx, rect);

    if (self.colors.count &lt; 1) {
        return;
    }
    else if (self.colors.count &lt; 2) {
        // There is only one color so directly draw with it
        CGColorRef color = (__bridge CGColorRef)(self.colors.firstObject);
        CGContextSetFillColorWithColor(ctx, color);
        CGContextFillRect(ctx, rect);
        return;
    }

    CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();

    size_t width = rect.size.width;
    size_t height = rect.size.height;

    size_t bitsPerCompoent = 8;
    size_t bytesPerRow = width * 4;

    size_t bitmapByteCount = bytesPerRow * height;

    uint32_t *bitmapData = calloc( bitmapByteCount / sizeof(uint32_t), sizeof(uint32_t) );

    // Map color to linear array each compoent occupy 1 byte
    uint8_t *colorCompoents = calloc(self.colors.count * 4, sizeof(uint8_t));

    for (int i = 0; i &lt; self.colors.count; ++i) {
        CGColorRef c = (__bridge CGColorRef)(self.colors[i]);

        const CGFloat *compoents = CGColorGetComponents(c);

        uint8_t red = compoents[0] * 255;
        uint8_t green = compoents[1] * 255;
        uint8_t blue = compoents[2] * 255;
        uint8_t alpha = compoents[3] * 255;

        int index = i * 4;
        *(colorCompoents + index) = red;
        *(colorCompoents + index + 1) = green;
        *(colorCompoents + index + 2) = blue;
        *(colorCompoents + index + 3) = alpha;
    }

    // Creating a Bitmap Graphics Context for conical gradient
    CGBitmapInfo bitmapInfo = kCGImageAlphaPremultipliedLast | kCGBitmapByteOrder32Little;

    CGContextRef bitmapGraphicsCtx = CGBitmapContextCreate(bitmapData, width, height, bitsPerCompoent, bytesPerRow, colorSpace, bitmapInfo);

    // Creating conical gradient from a Bitmap Graphics Context
    CGImageRef conicalGradientImage = CGBitmapContextCreateImage(bitmapGraphicsCtx);

    CGContextRelease(bitmapGraphicsCtx);

    free(colorCompoents);

    free(bitmapData);

    CGColorSpaceRelease(colorSpace);

    // Draws conical gradient image into a graphics context.
    CGContextDrawImage(ctx, rect, conicalGradientImage);

    CGImageRelease(conicalGradientImage);

    // Draws three concentric
    CGContextBeginPath(ctx);

    CGFloat halfWidth = 0.5 * CGRectGetWidth(rect);
    CGFloat maxRadii = 0.8 * halfWidth;
    CGFloat radii = floor(0.33 * maxRadii);

    for (int i = 1; i &lt; 4; ++i) {
        CGFloat r = radii * i;
        CGFloat dx = halfWidth - r;
        CGRect ellipseRect = CGRectInset(rect, dx, dx);

        CGContextAddEllipseInRect(ctx, ellipseRect);
    }

    CGContextSetRGBStrokeColor(ctx, 41/255.0, 234/255.0, 35/255.0, 1.0);
    CGContextStrokePath(ctx);
}

- (BOOL)needsDisplayOnBoundsChange
{
    return _needsDisplayOnBoundsChange;
}

- (void)setNeedsDisplayOnBoundsChange:(BOOL)needsDisplayOnBoundsChange
{
}
</code></pre>

<p>现在我们把架子搭起来了，但是还没有往位图里面填充颜色，在这之前，对这段代码稍作解释，首先是我覆盖了needsDisplayOnBoundsChange 属性的 getter 和 setter 方法，原因是我设置图层关联的背景颜色时会触发这个属性变 NO，导致 <code>drawInContext</code> 不会被调用，我认为这是 Apple 的一个 bug，已经作了反馈，所以这里我使用了这么一个绕过的方法。</p>

<p>其次，我把 RGB 颜色空间的颜色分量取出来放在了一个一维数组里用来备用；最后是 bitmapInfo 要或上 kCGBitmapByteOrder32Little，不然结果会不正确。</p>

<p>接下来就是要填充位图的颜色，代码如下：</p>

<pre><code>    // Create conical gradient bitmap data
    CGFloat centerX = width * 0.5;
    CGFloat centerY = height * 0.5;

    double baseAngle = 2*M_PI / (self.colors.count - 1);

    for (int i = 0; i &lt; height; ++i) {
        for (int j = 0; j &lt; width; ++j) {
            CGFloat x = j - centerX;
            CGFloat y = i - centerY;

            // define atan2 uniquely one uses the principal value in the range (−π, π]. That is, −π &lt; atan2(y, x) ≤ π.
            double angle = atan2(y, x);

            // Convert atan2 result angle to range [0, 2π]
            if (angle &lt; 0) {
                angle += 2 * M_PI;
            }

            // 0-360 map to linear gradient
            double angleRatio = angle / baseAngle;
            int colorIndex = angleRatio; // How many times of base angle?

            angle -= colorIndex * baseAngle;
            angleRatio = angle / baseAngle;

            colorIndex *= 4;

            uint8_t red0 = colorCompoents[colorIndex];
            uint8_t red1 = colorCompoents[colorIndex + 4];

            // Green index
            colorIndex += 1;
            uint8_t green0 = colorCompoents[colorIndex];
            uint8_t green1 = colorCompoents[colorIndex + 4];

            // Blue index
            colorIndex += 1;
            uint8_t blue0 = colorCompoents[colorIndex];
            uint8_t blue1 = colorCompoents[colorIndex + 4];

            // Alpha index
            colorIndex += 1;
            uint8_t alpha0 = colorCompoents[colorIndex];
            uint8_t alpha1 = colorCompoents[colorIndex + 4];

//            uint8_t red = red0 + angleRatio * (red1 - red0);
//            uint8_t green = green0 + angleRatio * (green1 - green0);
//            uint8_t blue = blue0 + angleRatio * (blue1 - blue0);
//            uint8_t alpha = alpha0 + angleRatio * (alpha1 - alpha0);

            uint8_t red = lerp(red0, red1, angleRatio);
            uint8_t green = lerp(green0, green1, angleRatio);
            uint8_t blue = lerp(blue0, blue1, angleRatio);
            uint8_t alpha = lerp(alpha0, alpha1, angleRatio);

            // Multiple alpha
            float a = alpha / 255.0;

            red *= a;
            green *= a;
            blue *= a;

            unsigned long index = i * width + j;

            *(bitmapData + index) = (red &lt;&lt; 24) | (green &lt;&lt; 16) | (blue &lt;&lt; 8) | alpha;
        }
    }
</code></pre>

<p>同样也稍微解释下其中的代码，首先是位图的填充要按照先行后列的顺序，行对就宽，列对应高；其次反正切函数的值域是(−π, π]，所以要把它们映射到[0, 2π]；然后我们根据角度对应的区间，选择起始和终点颜色，再由线性插值得到各自的颜色分量，实践中每个颜色分量还乘上了当前的透明度，最后合成该点的颜色。</p>

<p><a href="https://github.com/DamianSheldon/QuartzDemo">完整示例</a></p>

<h2>Reference:</h2>

<p><a href="https://stackoverflow.com/questions/15344163/conical-gradient-in-qt-without-qconicalgradient">Conical gradient in Qt (without QConicalGradient)</a><br/>
<a href="https://github.com/maxkonovalov/MKGradientView">MKGradientView</a><br/>
<a href="https://en.wikipedia.org/wiki/Color_gradient">Color gradient</a><br/>
<a href="https://en.wikipedia.org/wiki/Linear_interpolation">Linear interpolation</a><br/>
<a href="https://en.wikipedia.org/wiki/Atan2">atan2</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iOS 开发问题汇总(十)]]></title>
    <link href="http://DamianSheldon.github.io/blog/ios-development-problems-part-10.html"/>
    <updated>2017-09-11T15:42:24+08:00</updated>
    <id>http://DamianSheldon.github.io/blog/ios-development-problems-part-10</id>
    <content type="html"><![CDATA[<h3>1.在iOS 中如何使用私钥加密数据？</h3>

<p>A:当你用私钥加密时它被称为 siging, 之后用公钥解密的过程称为 verify signature.</p>

<blockquote><p>Why are you encrypting with the private key? When you encrypt with the private key, that is considered signing not encrypting, becuase it provides no confidentiality. If you want to &ldquo;encrypt&rdquo; with the private key, look into data signing, and that should allow you to &ldquo;encrypt&rdquo; (read &ldquo;sign&rdquo;) with the private key and &ldquo;decrypt&rdquo; (read &ldquo;verify signature&rdquo;) with the public key.</p></blockquote>

<p>Reference:</p>

<p><a href="https://stackoverflow.com/questions/6705928/encrypting-data-with-a-private-key-on-ios">Encrypting data with a private key on iOS</a></p>

<h3>2.</h3>

<pre><code>[!] Due to the previous naïve CocoaPods resolver, you were using a pre-release version of `JSONModel`, without explicitly asking for a pre-release version, which now leads to a conflict. Please decide to either use that pre-release version by adding the version requirement to your Podfile (e.g. `pod 'JSONModel', '= 1.2.2P'`) or revert to a stable version by running `pod update JSONModel`.
</code></pre>

<p>A:今天打开一个旧的的工程，可能由于版本控制的原因，Pods 下的文件都被删除掉了，于是运行 <code>pod install --verbose</code>, 安装报了上面的错误。工程是一个公共库，之前都是好的，它依赖了一个私有版本的 JSONModel,这本来也没什么问题，居然报出这么一错误，挺奇怪的。按提示先显示指定版本，依旧报错，看来并不是这个原因；又运行 <code>pod update JSONModel</code>,有输出安装私有版本的 JSONModel 的日志，问题解决。不过不清楚为什么会出这种很诡异的问题。</p>

<h3>3.What is the use of entitlements.plist file?</h3>

<p>A:</p>

<blockquote><p>Entitlements confer specific capabilities or security permissions to your iOS or macOS app.</p></blockquote>

<ol>
<li>The entitlements file defines certain capabilities of your app. Usually, the file is automatically generated by Xcode when you enable a capability for your app.</li>
<li>You only need the file if you enable certain capabilities, e.g. Healthkit integration. If you&rsquo;d like to use these features, you have to add it. Otherwise, Apple will reject your app.</li>
<li>You can name the file like you want. You can also rename it as long as the build settings point to the correct file name for it.</li>
</ol>


<p>Reference:</p>

<p><a href="https://stackoverflow.com/questions/26594367/what-is-the-use-of-entitlements-plist-file">What is the use of entitlements.plist file?</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iOS 中简单的图片处理]]></title>
    <link href="http://DamianSheldon.github.io/blog/simple-image-processing-in-ios.html"/>
    <updated>2017-07-14T09:49:40+08:00</updated>
    <id>http://DamianSheldon.github.io/blog/simple-image-processing-in-ios</id>
    <content type="html"><![CDATA[<p>在 iOS 应用开发中，我们可能会要对图片进行旋转、缩放和裁剪，在介绍具体方法前，我们有必要先对图片做个大致的了解，这样有助于我们选择合适的方法。</p>

<h3>图片格式</h3>

<p>图片主要有两种格式：一种叫做位图；另一种称之为矢量图。所谓位图，就是把图片看成是由许多像素点组成；而矢量图则是用绘图指令来描述图片。举个例子，圆可以用圆点，半径，线条的粗细和颜色来描述它。从这个例子也可以看出用矢量图来描述风景，人物这样复杂的事物会比较复杂，所以它们通常会用位图来描述。</p>

<p>位图和矢量图也分为很多格式，具体可能查看<a href="https://en.wikipedia.org/wiki/Image_file_formats">Image file formats</a></p>

<p>下面我们讨论的是位图，在 iOS 中我们经常打交道的位图格式是 JPG 和 PNG，用来处理位图数据的类有：UIImage (UIKit)，CGImage (Core Graphics) 和 CIImage (Core Image)。Image I/O 本来是属于 Core Graphics，为了更加方便使用，Apple 将它分离出来成为单独的库。</p>

<h3>旋转</h3>

<p>既然位图是用一个一个的像素点来模拟图片，当我们想要旋转图片时，首先想到的方法自然是改变这些像素点的位置，这当然可以达到目标。要调整这么多像素点的位置自然要耗费不少时间，所有在数码相机刚出来那会，人们不是去改变像素点的位置，而是用一段数据来描述图片的方向等信息，这段数据称为 Exif. 所以对于 JPG 这种拥有 Exif 信息的位图，我们旋转图片的最佳做法自然是改变 Exif 里的方向信息。而 PNG 是没有 Exif 信息的，所以只能改变像素点的位置。</p>

<p>UIImage 自带了几个可以旋转的方法：</p>

<pre><code>+ (UIImage *)imageWithCGImage:(CGImageRef)cgImage scale:(CGFloat)scale orientation:(UIImageOrientation)orientation;

+ (UIImage *)imageWithCIImage:(CIImage *)ciImage scale:(CGFloat)scale orientation:(UIImageOrientation)orientation;

- (instancetype)initWithCGImage:(CGImageRef)cgImage scale:(CGFloat)scale orientation:(UIImageOrientation)orientation;

- (instancetype)initWithCIImage:(CIImage *)ciImage scale:(CGFloat)scale orientation:(UIImageOrientation)orientation;
</code></pre>

<!--more-->


<p>我们没有这个方法的实现源码，但是我们可以输出图片的 Exif 信息来验证上面的说法。iOS 中我们可以使用 Image I/O 这个库来读取和修改图片的 Exif 信息。Image I/O 的文档不是很详细，使用时最好结合头文件的说明，而且要注意区分容器和单个图片，实验表明像方向这种信息它并不是放在 Exif 中，而是图片属性中，它的值和 UIImageOrientation 也不是一一对应的，它们的关系如下：</p>

<pre><code>typedef NS_ENUM(NSInteger, DMLImagePropertyOrientation) {
    DMLImagePropertyOrientationUp               = 1,
    DMLImagePropertyOrientationDown             = 3,
    DMLImagePropertyOrientationLeft             = 8,
    DMLImagePropertyOrientationRight            = 6,
    DMLImagePropertyOrientationUpMirrored       = 2,
    DMLImagePropertyOrientationDownMirrored     = 4,
    DMLImagePropertyOrientationLeftMirrored     = 5,
    DMLImagePropertyOrientationRightMirrored    = 7
};

+ (DMLImagePropertyOrientation)dml_imagePropertyOrientationFromUIImageOrientation:(UIImageOrientation)imageOrientation
{
    DMLImagePropertyOrientation imagePropertyOrientation = DMLImagePropertyOrientationUp;

    switch (imageOrientation) {
        case UIImageOrientationUp:
            imagePropertyOrientation = DMLImagePropertyOrientationUp;
            break;

        case UIImageOrientationDown:
            imagePropertyOrientation = DMLImagePropertyOrientationDown;
            break;

        case UIImageOrientationLeft:
            imagePropertyOrientation = DMLImagePropertyOrientationLeft;
            break;

        case UIImageOrientationRight:
            imagePropertyOrientation = DMLImagePropertyOrientationRight;
            break;

        case UIImageOrientationUpMirrored:
            imagePropertyOrientation = DMLImagePropertyOrientationUpMirrored;
            break;

        case UIImageOrientationDownMirrored:
            imagePropertyOrientation = DMLImagePropertyOrientationDownMirrored;
            break;

        case UIImageOrientationLeftMirrored:
            imagePropertyOrientation = DMLImagePropertyOrientationLeftMirrored;
            break;

        case UIImageOrientationRightMirrored:
            imagePropertyOrientation = DMLImagePropertyOrientationRightMirrored;
            break;
    }

    return imagePropertyOrientation;
}
</code></pre>

<p>从打印输出的内容看出 JPG 图片的方向确实改变了，然后我也写了个方法去改变图片的方向属性，得到了同样的效果，所以当我们是旋转上面提到的方向直接使用 UIImage 自带的几个旋转的方法应该是最佳选择，而要旋转任意角度，还是要通过调整像素点位置来完成。</p>

<pre><code>// 输出图片的属性信息
- (UIImageOrientation)dml_imageOrientationFromExif
{
    UIImageOrientation imageOrientation = UIImageOrientationRightMirrored + 1;

    NSData *dataOfImage = UIImageJPEGRepresentation(self, (CGFloat)0.7);

    CGImageSourceRef imageSource = CGImageSourceCreateWithData((__bridge CFDataRef)dataOfImage, NULL);

    CFDictionaryRef imageProperties = CGImageSourceCopyPropertiesAtIndex(imageSource, 0, NULL);

    NSLog(@"dml_imageOrientationFromExif image Properties:%@\n", (__bridge NSDictionary *)imageProperties);

    CFRelease(imageSource);

    CFNumberRef numberOfImageOrientation = CFDictionaryGetValue(imageProperties, kCGImagePropertyOrientation);

    CFRelease(imageProperties);

    DMLImagePropertyOrientation imagePropertyOrientation = [(__bridge NSNumber *)numberOfImageOrientation integerValue];

    imageOrientation = [[self class] dml_uiimageOrientationFromImagePropertyOrientation:imagePropertyOrientation];

    return imageOrientation;
}

// 修改图片的方向属性
- (UIImage *)dml_setExifOritenation:(UIImageOrientation)imageOrientation error:(NSError * __autoreleasing *)error
{
    NSData *dataOfImage = UIImageJPEGRepresentation(self, (CGFloat)0.7);

    CGImageSourceRef imageSource = CGImageSourceCreateWithData((__bridge CFDataRef)dataOfImage, NULL);

    /* get the file type */
    CFStringRef UTI = CGImageSourceGetType(imageSource);
    if ( NULL == UTI ) {
        /* Handle Error Retrieving File Type Accordingly */
        if (error) {
            *error = [NSError errorWithDomain:(__bridge NSString *)kCFErrorDomainCGImageMetadata code:kCGImageMetadataErrorUnknown userInfo:@{NSLocalizedDescriptionKey: @"Handle Error Retrieving File Type Accordingly"}];
        }
        return nil;
    }

//    CFMutableDataRef finalImageData = (__bridge_retained CFMutableDataRef)dataOfImage.mutableCopy;
    CFMutableDataRef finalImageData = (__bridge_retained CFMutableDataRef)[NSMutableData new];

    /* create an image destination for saving the file */
    CGImageDestinationRef destination = CGImageDestinationCreateWithData(finalImageData, UTI, 1, NULL);
    if ( nil == destination ) {
        /* Handle Error Creating CGImageDestinationRef Accordingly */
        if (error) {
            *error = [NSError errorWithDomain:(__bridge NSString *)kCFErrorDomainCGImageMetadata code:kCGImageMetadataErrorUnknown userInfo:@{NSLocalizedDescriptionKey: @"Handle Error Creating CGImageDestinationRef Accordingly"}];
        }
        return nil;
    }

    /* setting properties */
//    CFDictionaryRef sourceProperties = CGImageSourceCopyProperties(imageSource, NULL);
    CFDictionaryRef sourceProperties = CGImageSourceCopyPropertiesAtIndex(imageSource, 0, NULL);

    NSLog(@"dml_setExifOritenation original properties:%@\n", (__bridge NSDictionary *)sourceProperties);

    CFMutableDictionaryRef mutableSourceProperties = CFDictionaryCreateMutableCopy(kCFAllocatorDefault, CFDictionaryGetCount(sourceProperties) + 1, sourceProperties);

    DMLImagePropertyOrientation imagePropertyOrientation = [[self class] dml_imagePropertyOrientationFromUIImageOrientation:imageOrientation];

    CFNumberRef numberForOritentation = CFNumberCreate(kCFAllocatorDefault, kCFNumberNSIntegerType, &amp;imagePropertyOrientation);

    CFDictionarySetValue(mutableSourceProperties, kCGImagePropertyOrientation, numberForOritentation);

    NSLog(@"dml_setExifOritenation edited properties:%@\n", (__bridge NSDictionary *)mutableSourceProperties);

    CGImageDestinationAddImageFromSource(destination, imageSource, 0, mutableSourceProperties);
    CGImageDestinationFinalize(destination);

    UIImage *resultImage = [UIImage imageWithData:(__bridge NSData *)finalImageData];

    CFRelease(numberForOritentation);

    CFRelease(mutableSourceProperties);

    CFRelease(sourceProperties);

    // Print destination properties

    NSData *dataOfDestinationImage = UIImageJPEGRepresentation(resultImage, (CGFloat)0.7);

    CGImageSourceRef destinationImageSource = CGImageSourceCreateWithData((__bridge CFDataRef)dataOfDestinationImage, NULL);

    CFDictionaryRef properties = CGImageSourceCopyPropertiesAtIndex(destinationImageSource, 0, NULL);

    NSLog(@"destination properties:%@\n", (__bridge NSDictionary *)properties);

    CFRelease(properties);
    CFRelease(destinationImageSource);

    return resultImage;
}
</code></pre>

<p>PS.理论上来讲，我们可以使用 <code>void CGImageDestinationSetProperties(CGImageDestinationRef idst, CFDictionaryRef properties);</code> 搭配 <code>bool CGImageDestinationCopyImageSource(CGImageDestinationRef idst, CGImageSourceRef isrc, CFDictionaryRef options, CFErrorRef  _Nullable *err);</code> 来改变图片的属性的，实际实验中并没有达到预期效果，原因不明。</p>

<h3>缩放</h3>

<p>上面提到 UIImage 的旋转方法也可以指定 Scale 因子，它是我们常说的几倍图中这个几倍因子，如果图片本来是一倍图，然后我们欺骗这个方法说是0.5倍图，那么我们会得到一张放大2倍的图，以些类推，所以我们可以考虑用这个方法来满足我们的一些简单需求，不能满足时，我们可以用 Core Graphics 将图片画到目标大小的位图上下文中来得到我们想要的图片。</p>

<h3>裁剪</h3>

<p>UIImage 没有裁剪相关的方法，我们可以使用 Core Graphics 中的 <code>CGImageRef CGImageCreateWithImageInRect(CGImageRef image, CGRect rect);</code>方法来实现裁剪。使用这个方法我们需要注意 Rect 要考虑图片的 scale，图片完整的 <code>rect = {0, 0, image.size.width * image.scale, image.size.height * image.scale}</code>, 所以我们指定裁剪的 rect 时也要带上 scale.</p>

<h3>缩略图</h3>

<p>生成缩略图可以使用 Image I/O 中的 <code>CGImageRef CGImageSourceCreateThumbnailAtIndex(CGImageSourceRef isrc, size_t index, CFDictionaryRef options);</code>方法。</p>

<h3>Reference</h3>

<ul>
<li>Image I/O Programming Guide</li>
<li><a href="https://objccn.io/issue-21-2/">图片格式</a></li>
<li><a href="http://nshipster.com/image-resizing/">Image Resizing Techniques</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[输出自定义尺寸视频]]></title>
    <link href="http://DamianSheldon.github.io/blog/how-to-specify-a-resolution-for-output-video.html"/>
    <updated>2017-04-10T10:12:09+08:00</updated>
    <id>http://DamianSheldon.github.io/blog/how-to-specify-a-resolution-for-output-video</id>
    <content type="html"><![CDATA[<p>最近要做的一个项目中要拍摄视频，于是就开始来研究视频。看了几遍 AVFoundation Programming Guide 之后也写了个 Demo，把基本功能都过了一遍。这其中有意思的一件事情是我发现微信拍摄短视频的尺寸是 540x944, 这尺寸很奇怪，不是任何一个预设值。不清楚微信为什么用这么一个尺寸，但我想搞清楚怎么输出自定义尺寸的视频。</p>

<p>AVFoundation 捕获数据输出时，各组件的关系如下：</p>

<div style="text-align:center" markdown="1">
                                                                                           <img name="Capture Detail" src="http://DamianSheldon.github.io/images/captureDetail_2x.png">
                                                                                        </div>


<p>要想输出自定义尺寸的视频，我们可以从输入端和输出端着手。但是从文档来看，并没有提供可以自定捕获尺寸的方法，所以只能从输出端着手。</p>

<!--more-->


<p>首先我用 AVCaptureMovieFileOutput 做输出，然后调用 <code>setOutputSettings(_ outputSettings: [AnyHashable : Any]!, for connection: AVCaptureConnection!)</code> 来达到目标。但是很不幸，控制台输出了异常，查看 AVCaptureMovieFileOutput 的头文件，</p>

<blockquote><p>On iOS, you may only specify the AVVideoCodecKey in the outputSettings. If you specify any other key, an NSInvalidArgumentException will be thrown. See the availableVideoCodecTypes property.</p></blockquote>

<p>所以这个方法行不通。</p>

<p>于是我又尝试用 AVAssetWriter 来接收每一帧捕获的数据，然后按配置输出，理论上来讲这是可行的，实际上只有第一帧数据能成功被接收，之后的数据都会接收失败，具体原因不详。</p>

<p>直接处理每一帧数据失败之后，我又反复翻阅文档，发现编辑章节中提到可以修改 renderSize, 于是又一个想法冒出来，也许可以通过修改 renderSize 来输出自定义尺寸。按照文档编写好相关代码，激动地运行测试。结果得到的是：</p>

<pre><code>Optional(Error Domain=AVFoundationErrorDomain Code=-11800 "The operation could not be completed" UserInfo={NSUnderlyingError=0x1700505c0 {Error Domain=NSOSStatusErrorDomain Code=-12108 "(null)"}, NSLocalizedFailureReason=An unknown error occurred (-12108), NSLocalizedDescription=The operation could not be completed})
</code></pre>

<p>说实话，内心是崩溃的。但对这件事情还是耿耿于怀，又浏览了一下官方示例列表，发现了 AVSimpleEditoriOS,</p>

<blockquote><p>AVSimpleEditor is a simple AVFoundation based movie editing application which exercises the APIs of AVVideoComposition, AVAudioMix and demonstrates how they can be used for simple video editing tasks. It also demonstrates how they interact with playback (AVPlayerItem) and export (AVAssetExportSession). The application performs trim, rotate, crop, add music, add watermark and export. This sample is ARC-enabled.</p></blockquote>

<p>嗯，看到里面提到可以裁剪，于是就想它是怎么做？可以剪成我想要的大小吗？阅读相关的代码片断，原来它就是用的 renderSize 来实现裁剪的，跟我第三种方法的代码基本一致，差别是它是 Objc 写的，我用 Swift 写的。既然它能正常工作，那我就用这份代码来输出自定义尺寸吧。把代码移进来，运行测试，居然输出了指定的尺寸，难道代码用 Objc 和 Swift 写还有这种差别，整个人是懵的，这个原因暂时是不清楚的。</p>

<p>虽然输出的尺寸对了，但是画面没有铺满尺寸，而且方向错了。这有点太虐了，既然都走到这一步，就想那我再试试能不手动把它纠正吧。纠正的方法是使用 transform, 但是文档对它的介绍不详细，我先参考了 QuartZ 2D Programming Guide 中 Transforms 来变换，发现不对，整个画面全变成了黑色，又在 AVSimpleEditoriOS 的注释中发现了新的线索，</p>

<blockquote><p>Note: the point of origin for rotation is the upper left corner of the composition, t3 is to compensate for origin</p></blockquote>

<p>这么说它用的坐标和 QuartZ 2D 还不一样啊，这么坑爹，好吧，只能先确定好它们是怎么变换的。于是我先输出一段没变换的视频，之后每次测试一个变换，用这个办法确认了它们的变换是这样的，变换的原点是屏幕的左上角，Translation 向右是 X 轴的正方向，向下是 Y 轴的正方向; Rotation 的度数为正是按顺时针方向旋转，为负则是逆时针方向旋转；Scaling 的值大于1为放大，小于1则是缩小。</p>

<p>这样我就做了这么一个变换：</p>

<pre><code>t1 = CGAffineTransformScale(asset.preferredTransform, sx, sy);

t1 = CGAffineTransformRotate(t1, degreesToRadians(90));

t1 = CGAffineTransformTranslate(t1, 540, 0);
</code></pre>

<p>控制台报错了，说这个视频不支持编辑，这是个什么鬼？完全没有道理啊！于是我又把这段代码从下往上一行一行注释，看是谁导致的问题，发现是 <code>t1 = CGAffineTransformRotate(t1, degreesToRadians(90));</code> ，这样我又试着调整变换的顺序，改成：</p>

<pre><code>t1 = CGAffineTransformTranslate(asset.preferredTransform, 540, 0);

t1 = CGAffineTransformScale(t1, sx, sy);

t1 = CGAffineTransformRotate(t1, degreesToRadians(90));
</code></pre>

<p>运行测试，苍天啊，居然可以了。经历这么一出，感觉写代码都成了玄学了, 无力吐槽!</p>
]]></content>
  </entry>
  
</feed>
